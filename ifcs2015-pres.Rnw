\documentclass[10pt]{beamer}

\usepackage[utf8]{inputenc}
\usepackage{color}
\usepackage{tikz}
\usepackage{mathtools}
\usepackage{array}
\usepackage{amsmath, amssymb, bbm}
\usepackage{verbatim}
\usepackage{relsize}
\usepackage{multirow}
\usepackage{rotating}
\usepackage{ragged2e}
\usepackage{soul}
%\usetheme{Warsaw}
%\usepackage{dsfont}
%\usecolortheme{lily}

\definecolor{obs}{RGB}{53,106,160}
\definecolor{post}{RGB}{0,110,46}
\definecolor{class}{RGB}{160,110,46}
\definecolor{idea}{RGB}{162,162,162}

\definecolor{gg1}{RGB}{248,118,109}
\definecolor{gg2}{RGB}{183,159,0}
\definecolor{gg3}{RGB}{0,186,56}
\definecolor{gg4}{RGB}{0,191,196}
\definecolor{gg5}{RGB}{97,156,255}
\definecolor{gg6}{RGB}{245,100,227}

\newcommand{\obs}[1]{{\color{obs}#1}}
\newcommand{\post}[1]{{\color{post}#1}}
\newcommand{\class}[1]{{\color{class}#1}}
\newcommand{\idea}[1]{{\color{idea}#1}}
\newcommand{\tidea}[2]{{\uncover<#1>{\color{idea}#2}}}
\newcommand{\red}[1]{{\color{red}#1}}
\newcommand{\blue}[1]{{\color{blue}#1}}

\newcommand{\gga}[1]{{\color{gg1}#1}}
\newcommand{\ggb}[1]{{\color{gg2}#1}}
\newcommand{\ggc}[1]{{\color{gg3}#1}}
\newcommand{\ggd}[1]{{\color{gg4}#1}}
\newcommand{\gge}[1]{{\color{gg5}#1}}
\newcommand{\ggf}[1]{{\color{gg6}#1}}

\title{An integrated formulation for merging mixture components based on posterior probabilities}
\subtitle{IFCS 2015, Bologna}
\author{\emph{Marc~Comas-Cufí} \\ \and Josep~Antoni~Martín-Fernández \\\and Glòria~Mateu-Figueras}
\institute{Universitat de Girona}
\date{July 8th, 2015}

\begin{document}


\begin{frame}
\titlepage
\end{frame}

<<echo=FALSE, include=FALSE>>=
knitr::opts_chunk$set(comment=NA, echo=FALSE)
library(ggplot2)
library(mclust)
library(dplyr)
library(mixpack)
library(grid)
library(gridBase)
options(width=200)
knitr::opts_chunk$set(comment = " ", echo = FALSE, warning = FALSE)
rnormmix = function(n, pi= c(1/3, 1/3, 1/3), 
                    mean = c(-2, 0, 2),
                    sd = c(1, 1, 1)){
  df = apply(cbind(mean, sd), 1, function(pars) rnorm(n, mean=pars[1], sd=pars[2]))
  z = sapply(sample(1:3, size = n, replace = TRUE, prob = pi), function(i) 1:3 == i)
  df[t(z)]
}
dnormmix = function(x, pi= c(1/3, 1/3, 1/3), 
                    mean = c(-2, 0, 2),
                    sd = c(1, 1, 1)){
  df = apply(cbind(pi, mean, sd), 1, function(pars) pars[1] * dnorm(x, mean=pars[2], sd=pars[3]))
  apply(df, 1, sum)
}
cnormmix = function(x, pi= c(1/3, 1/3, 1/3), 
                    mean = c(-2, 0, 2),
                    sd = c(1, 1, 1),
                    class = 1:length(pi)){
  df = apply(cbind(pi, mean, sd), 1, function(pars) pars[1] * dnorm(x, mean=pars[2], sd=pars[3]))
  as.factor(class[apply(df, 1, which.max)])
}
get_sample = function(seed = 2){
  set.seed(seed)
  Pi = c(2/9, 4/9, 3/9)
  Mean = c(-2, 3.5, 5)
  Sd = c(0.65,1.2,0.8)
  df = data.frame('x' = rnormmix(n = 100,  pi = Pi, mean = Mean, sd = Sd))
  df$f = dnormmix(df$x, pi = Pi, mean = Mean, sd = Sd)
  df$class = cnormmix(df$x, pi = Pi, mean = Mean, sd = Sd)
  df$class2 = cnormmix(df$x, pi = Pi, mean = Mean, sd = Sd, class=c(1,2,2))
  df$f1 = Pi[1] * dnorm(df$x, mean = Mean[1], sd = Sd[1]) / df$f
  df$f2 = Pi[2] * dnorm(df$x, mean = Mean[2], sd = Sd[2]) / df$f
  df$f3 = Pi[3] * dnorm(df$x, mean = Mean[3], sd = Sd[3]) / df$f
  df.dens = data.frame('x' = seq(-5, 10, 0.2))
  df.dens$f = dnormmix(df.dens$x, pi = Pi, mean = Mean, sd = Sd)
  df.dens$f1 = Pi[1] * dnorm(df.dens$x, mean = Mean[1], sd = Sd[1])
  df.dens$f2 = Pi[2] * dnorm(df.dens$x, mean = Mean[2], sd = Sd[2])
  df.dens$f3 = Pi[3] * dnorm(df.dens$x, mean = Mean[3], sd = Sd[3])
  list('sample' = df, 'density' = df.dens)
}
@

\section{Introduction to the problem of merging components}

\begin{frame}
\frametitle{How many groups do you see here?}
\begin{itemize}
\item Consider the following sample $X = \{x_1,\dots,x_{100} \}$:
\end{itemize}

\begin{columns}[T]
\begin{column}{0.6\textwidth}
\only<1>{
<<fig.width=4, fig.height=3>>=
v_xlim = c(-5, 8)
X = get_sample()
df = X$sample
df.dens = X$density

(p1 <- ggplot() + 
  geom_histogram(data=df, aes(x=x, y = ..density..), binwidth=0.5, col='black', fill='white') +
  geom_segment(data=df, aes(x=x, xend=x, y=0, yend=0.01), alpha=1) +
  theme_bw() + xlim(v_xlim) + theme(axis.ticks.y = element_blank(), axis.text.y = element_blank(),  panel.grid=element_blank()) +
  ylab(NULL) + xlab(NULL))
@
}
\only<2>{
<<fig.width=4, fig.height=3>>=
df$km = ifelse(df$x < 0, '1', '2')
ggplot() + 
  geom_histogram(data=df, aes(x=x, fill=km), binwidth=0.5, alpha=0.15, col='black') +
  geom_segment(data=df, aes(x=x, xend=x, y=0, yend=0.5, col=km), alpha=1) +
  theme_bw() + xlim(v_xlim) + theme(axis.ticks.y = element_blank(), axis.text.y = element_blank(),  panel.grid=element_blank()) +
  ylab(NULL) + xlab(NULL)  + theme(legend.position="none")
@
}
\end{column}
\end{columns}
\end{frame}

<<fr1, child='fr1.Rnw'>>=
@

\section{Merging components based on the posterior probabilities}

<<frm_problem, child='frm_problem.Rnw'>>=
@

\section{Our proposal: a generic merging method}

\begin{frame}
\frametitle{A generic merging method}

Given the set of components $\mathcal{I}_s = \{I_1, \dots, I_s\}$ and $\mathcal{T}_{\mathcal{I}_s} = \{\tau_{1 \mathcal{I}_s}, \dots, \tau_{n \mathcal{I}_s} \}$, we propose to merge those two components $I_a$ and $I_b$, into one component $I_a \cup I_b$ which maximise
\[
S_{\omega, \lambda}( \mathcal{T}_{\mathcal{I}_s}, I_a, I_b) = \frac{\sum_{i=1}^n {\color{blue}{\omega(\tau_{i \mathcal{I}_s}, I_a, I_b)}} {\color{red}{\lambda(\tau_{i \mathcal{I}_s}, I_a, I_b)}}}{\sum_{i=1}^n {\color{blue}{\omega(\tau_{i \mathcal{I}_s}, I_a, I_b)} }},
\]

where 
\begin{itemize}
\item the function ${\color{red}{\lambda(\tau_{i \mathcal{I}_s}, I_a, I_b)}}$ measures how likely is to merge component $I_a$ and $I_b$ given the information contained in $\tau_{i \mathcal{I}_s}$ and
\item the function ${\color{blue}{\omega(\tau_{i \mathcal{I}_s}, I_a, I_b)}}$ measures how relevant is observation $i$ to compute the overall score to merge $I_a$ and $I_b$ given the information contained in $\tau_{i \mathcal{I}_s}$.
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Existing approaches and extensions}

\begin{center}
\scriptsize
\[
S_{\omega, \lambda}( \mathcal{T}_{\mathcal{I}_s}, I_a, I_b) = \frac{\sum_{i=1}^n {\color{blue}{\omega(\tau_{i \mathcal{I}_s}, I_a, I_b)}} {\color{red}{\lambda(\tau_{i \mathcal{I}_s}, I_a, I_b)}}}{\sum_{i=1}^n {\color{blue}{\omega(\tau_{i \mathcal{I}_s}, I_a, I_b)} }},
\]
\end{center}

\begin{itemize} 
\item The DEMP approach. Hennig (2010)
\begin{itemize} \item ${\color{blue}{\omega(\tau_{i \mathcal{I}_s}, I_a, I_b)}} = \tau_{i I_{a}}$ \item ${\color{red}{\lambda(\tau_{i \mathcal{I}_s}, I_a, I_b)}} = \mathbbm{1} \left( \forall j\; \tau_{i I_{b}} \geq \tau_{iI_j} \right)$ \end{itemize}
\item The entropy approach. Baudry et el. (2010)
\begin{itemize} \item ${\color{blue}{\omega(\tau_{i \mathcal{I}_s}, I_a, I_b)}} = 1$ \item ${\color{red}{\lambda(\tau_{i \mathcal{I}_s}, I_a, I_b)}} = (\tau_{i I_a}+\tau_{i I_b}) \log(\tau_{i I_a} + \tau_{i I_b}) - \left\{ \tau_{i I_a} \log(\tau_{i I_a}) + \tau_{i I_b} \log(\tau_{i I_b})\right\}$ \end{itemize}
\item Longford \& Bartosova. Longford \& Bartosova (2014)
\begin{itemize} \item ${\color{blue}{\omega(\tau_{i \mathcal{I}_s}, I_a, I_b)}} = 1$ \item ${\color{red}{\lambda(\tau_{i \mathcal{I}_s}, I_a, I_b)}} = \frac{\tau_{i I_{b}}}{\tau_{i I_{a}} + \tau_{i I_{b}}}$ \end{itemize}
\item<3-> ${\color{blue}{\omega(\tau_{i \mathcal{I}_s}, I_a, I_b)}} = \mathbbm{1} \left( \forall j\; \tau_{i I_{a}} \geq \tau_{iI_j} \right)$
\item<4->  ${\color{red}{\lambda(\tau_{i \mathcal{I}_s}, I_a, I_b)}} = \tau_{i I_{b}}$
\end{itemize}

\begin{table}[ht]
\scriptsize
\centering
\begin{tabular}{llll}
  \hline
  ${\color{red}{\lambda}}$ $\backslash$ ${\color{blue}{\omega}}$ & {\color{blue}{cnst}} & {\color{blue}{prop}} & \uncover<3->{{\color{blue}{dich}}} \\ 
  \hline
 {\color{red}demp} & \uncover<2->{cnst-demp} & {\color{gg3}Hennig (2010)} & \uncover<3->{dich-demp}\\ 
 {\color{red}demp.mod} & {\color{gg3}Longford \& Bartosova (2014)} & \uncover<2->{prop-demp.mod} & \uncover<3->{dich-demp.mod}\\ 
 {\color{red}entr} & {\color{gg3}Baudry et al. (2010)} & \uncover<2->{prop-entr} & \uncover<3->{dich-entr}\\ 
 \uncover<4->{\color{red}prop} & \uncover<4->{cnst-prop} & \uncover<4->{prop-prop} & \uncover<4->{dich-prop}\\ 
   \hline
\end{tabular}
\end{table}

\end{frame}

\section{Defining new approaches}
\begin{frame}
\frametitle{Compositional data}

\begin{itemize}
\item Compositional data is data defined on the simplex space, which is defined as
\[
\mathcal{S}^k = \{ (\tau_1, \dots, \tau_k) : \tau_i > 0 (i = 1, 2, \dots, k), \sum_{i=1}^k \tau_i = 1 \text{ and } \}
\]
\item Compositional data carries only relative information, therefore, only ratios (or log-ratios) between components are of interest.
\item The set $\mathcal{S}^k$ is a $(k-1)$-dimensional Euclidean space.
\item To measure the relation between two components, we restrict to subcomposition $(\tau_{i I_a}, \tau_{i I_b})$
\begin{itemize}
\item The Log-ratio approach
\[
{\color{red}{\lambda(\tau_{i \mathcal{I}_s}, I_a, I_b)}} = log(\tau_{i I_b}/ \tau_{i I_a})
\]
\item The Aitchison norm
\[
{\color{red}{\lambda(\tau_{i \mathcal{I}_s}, I_a, I_b)}} = - log(\tau_{i I_b}/ \tau_{i I_a})^2
\]
\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Shown methods}
\begin{table}[ht]
\scriptsize
\centering
\begin{tabular}{llll}
  \hline
  ${\color{red}{\lambda}}$ $\backslash$ ${\color{blue}{\omega}}$ & {\color{blue}{cnst}} & {\color{blue}{prop}} & {\color{blue}{dich}} \\ 
  \hline
 \color{red}coda & cnst-coda & prop-coda & dich-coda\\
 \color{red}coda.norm & cnst-coda.norm & prop-coda.norm & dich-coda.norm\\
 \color{red}demp & cnst-demp & {\color{gg3}Hennig (2010)} & dich-demp\\ 
 \color{red}demp.mod & {\color{gg3}Longford \& Bartosova (2014)} & prop-demp.mod & dich-demp.mod\\ 
 \color{red}entr & {\color{gg3}Baudry et al. (2010)} & prop-entr & dich-entr\\ 
 \color{red}prop & cnst-prop & prop-prop & dich-prop\\
   \hline
\end{tabular}
\end{table}

\begin{columns}[T]
\begin{column}{0.9\textwidth}
<<r, fig.width=9, fig.height=5>>=
load('sim01/data/res_NSIM_050-NDATA_200-K0_003-Kf_009-DIM_005-SEED_001.RData')
res.mean = res %>% group_by(omega, lambda, overlap, method) %>% summarise(AR = mean(AR))
res.mean$omega = factor(res.mean$omega, levels = c('cnst', 'prop', 'dich'))
ggplot() + geom_line(data = res.mean, aes(x = overlap, y = AR, col = method)) + 
  facet_grid(omega~lambda) + theme_bw()
@
\end{column}
\end{columns}

\end{frame}

\section{Experiment: comparinig the results for each approach}


\end{document}