---
title: "An integrated formulation for merging mixture components based on posterior probabilities (IFCS'15)"
author: "Marc Comas-Cufí, Josep Antoni Martín-Fernández and Glòria Mateu-Figueras"
date: "July 8th, 2015"
output: 
  html_document: 
    theme: cosmo
    toc: yes
---

```{r, include=FALSE}
library(ggplot2)
library(mclust)
library(dplyr)
library(mixpack)
library(grid)
library(gridBase)
library(abind)
options(width=200)
knitr::opts_chunk$set(comment = " ", echo = FALSE, warning = FALSE)

source('testing_samples.R')
X = test1(100)
```

# Introduction to the problem of merging components

In this talk we focus on methods used to merge the components of a finite mixture model hierarchically, in such a way that the merged components are considered as a unique component. Doing so, when we cluster our observations using the finite mixture distribution, we can consider the merged components to be a unique cluster. 

<video controls="controls" loop="loop"><source src="merging_animation.webm" />Merging animation</video>


# Merging components based on the posterior probabilities

We propose to merge the components of a finite mixture using the information contained only in the posterior probabilities.

Given a sample of probabilities to belong to each component $I_j$,

\[ \left[ \begin{array}{ccccc}
(\tau_{11}, & \dots & \tau_{1j}, & \dots & \tau_{1k}), \\
\vdots      & &    \vdots                     & &    \vdots                     \\
(\tau_{i1}, & \dots & \tau_{ij}, & \dots & \tau_{ik}), \\
\vdots      & &      \vdots                   & &       \vdots                  \\
(\tau_{n1}, & \dots & \tau_{nj}, & \dots & \tau_{nk})
\end{array} \right] 
\in \mathcal{S}^k \]

merge the components (sequentially) to obtain a hierarchy over the set of components.

# Our proposal: a general merging score

Given the set of components $\mathcal{I}_s = \{I_1, \dots, I_s\}$ and $\mathcal{T}_{\mathcal{I}_s} = \{\tau_{1 \mathcal{I}_s}, \dots, \tau_{n \mathcal{I}_s} \}$, we propose to merge those two components $I_a$ and $I_b$, into one component $I_a \cup I_b$ which maximise
\[
S_{\omega, \lambda}( \mathcal{T}_{\mathcal{I}_s}, I_a, I_b) = \frac{\sum_{i=1}^n \color{blue}{\omega(\tau_{i \mathcal{I}_s}, I_a, I_b)} \color{red}{\lambda(\tau_{i \mathcal{I}_s}, I_a, I_b)}}{\sum_{i=1}^n \color{blue}{\omega(\tau_{i \mathcal{I}_s}, I_a, I_b)} }.
\]

  * The function $\color{red}{\lambda(\tau_{i \mathcal{I}_s}, I_a, I_b)}$ measures how likely is to merge component $I_a$ and $I_b$ given the information contained in $\tau_{i \mathcal{I}_s}$.
  * The function $\color{blue}{\omega(\tau_{i \mathcal{I}_s}, I_a, I_b)}$ measures how relevant is observation $i$ to compute the overall score to merge $I_a$ and $I_b$ given the information contained in $\tau_{i \mathcal{I}_s}$.

## Particular cases:
### The DEMP approach [Hennig (2010)]

  * $\color{blue}{\omega(\tau_{i \mathcal{I}_s}, I_a, I_b)} = \tau_{i I_{b}}$ and $\color{red}{\lambda(\tau_{i \mathcal{I}_s}, I_a, I_b)} = \mathbb{1}\left( \forall j\; \tau_{i I_{b}} \geq \tau_{iI_j} \right)$

### The entropy approach [Baudry et el. (2010)]

  * $\color{blue}{\omega(\tau_{i \mathcal{I}_s}, I_a, I_b)} = 1$ and $\color{red}{\lambda(\tau_{i \mathcal{I}_s}, I_a, I_b)} = (\tau_{i I_a}+\tau_{i I_b}) \log(\tau_{i I_a} + \tau_{i I_b}) - \left\{ \tau_{i I_a} \log(\tau_{i I_a}) + \tau_{i I_b} \log(\tau_{i I_b})\right\}$

### Longford & Bartosova [Longford & Bartosova (2014)]

Using the posterior probabilities $\mathcal{T}_{\mathcal{I}_s}^*$ of a simulated sample from components $\mathcal{I}_s = \{I_1, \dots, I_s\}$

  * $\color{blue}{\omega(\tau_{i \mathcal{I}_s}, I_a, I_b)} = 1$ and $\color{red}{\lambda(\tau_{i \mathcal{I}_s}, I_a, I_b)} = \frac{\tau_{i I_{b}}}{\tau_{i I_{a}} + \tau_{i I_{b}}}$

### The log-ratio criterias

  * Consider $\color{red}{\lambda(\tau_{i \mathcal{I}_s}, I_a, I_b)} = log(\tau_{i I_{b}} / \tau_{i I_{a}})$

### The Aitchison distance criteria

  * Consider $\color{red}{\lambda(\tau_{i \mathcal{I}_s}, I_a, I_b)} = - log(\tau_{i I_{b}} / \tau_{i I_{a}})^2$

## Experiment: comparing the results for each aproach

We have considered the following experiment. 

  * For differents values of $\hat{\omega} \in (0, 0.5)$,
  
    1. Generate a $X$ sample of $N_{\text{data}}$ observations following a mixtures of $K_0$ components. For each element from sample $X$ keep the label from the component it was generated to obtain a labeling $L_0$. The mixtures components are separated with fixed $\hat{\omega}$ maxoverlapping measure.
    2. Fit a mixture with $K_f$ components ($K_f > K_0$) to sample $X$ and calculate the posterior probabilities $\tau_i = \left(\tau_{i1}, \dots, \tau_{i K_f}\right)$ for each element $x_i \in X$ to obtain $T = \{ \tau_1, \dots, \tau_{N_{\text{data}}} \}$.
    3. Obtain a hierachy $\mathcal{H}$ over the $K_f$ components using a fixed function $\color{red}{\lambda}$ and $\color{blue}{\omega}$.
    4. Compare the classification given at level $K_0$ of hierarchy $\mathcal{H}$ with the classification given by $L_0$ obtaining and score $s_i$.

For each function $\color{red}{\lambda}$ and $\color{blue}{\omega}$ we have repeated the experiment $N_\text{sim}$ times and computes the mean $\bar{s} = \sum_{i=1}^{N_\text{sim}} s_i$

### Results 

* $N_{\text{sim}} = 50$, $N_{\text{data}} = 200$, $K_0=3$, $K_f=9$, $\text{seed}=1$ and $\text{dimension}=5$.

```{r, fig.width=9, fig.height=5}
load('sim01/data/res_NSIM_050-NDATA_200-K0_003-Kf_009-DIM_005-SEED_001.RData')
res.mean = res %>% group_by(omega, lambda, overlap, method) %>% summarise(AR = mean(AR))
ggplot() + geom_line(data = res.mean, aes(x = overlap, y = AR, col = method)) + 
  facet_grid(omega~lambda) + theme_bw()
```

* $N_{\text{sim}} = 50$, $N_{\text{data}} = 200$, $K_0=3$, $K_f=12$, $\text{seed}=1$ and $\text{dimension}=5$.

```{r, fig.width=9, fig.height=5}
load('sim01/data/res_NSIM_050-NDATA_200-K0_003-Kf_012-DIM_005-SEED_001.RData')
res.mean = res %>% group_by(omega, lambda, overlap, method) %>% summarise(AR = mean(AR))
ggplot() + geom_line(data = res.mean, aes(x = overlap, y = AR, col = method)) + 
  facet_grid(omega~lambda) + theme_bw()
```

* $N_{\text{sim}} = 50$, $N_{\text{data}} = 200$, $K_0=3$, $K_f=9$, $\text{seed}=1$ and $\text{dimension}=10$.

```{r, fig.width=9, fig.height=5}
load('sim01/data/res_NSIM_050-NDATA_200-K0_003-Kf_009-DIM_010-SEED_001.RData')
res.mean = res %>% group_by(omega, lambda, overlap, method) %>% summarise(AR = mean(AR))
ggplot() + geom_line(data = res.mean, aes(x = overlap, y = AR, col = method)) + 
  facet_grid(omega~lambda) + theme_bw()
```